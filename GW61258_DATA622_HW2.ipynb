{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79718f5c-7a13-4901-bb4b-d7f2066b70b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b72f9-2d54-44c6-8f77-ff4ce26871c4",
   "metadata": {},
   "source": [
    "### Step 1: Read the Webpage\n",
    "Here, I use the requests library to obtain the HTML content of the page.\n",
    "I then print the first 700 characters so we can see what raw HTML looks like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd140b7a-4c3c-4a51-9653-749a19f4542e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sanketpatil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sanketpatil/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/sanketpatil/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dowmloading the nltk datasets (stopwords + wordnet) just in case not already\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf7b4de-9cd6-4cac-903b-d471a97c6410",
   "metadata": {},
   "source": [
    "### Step 2: Remove HTML Tags\n",
    "Here I use **BeautifulSoup** to strip away all HTML tags (like `<div>`, `<p>`, etc.) and keep only plain readable text.  \n",
    "I again print the first 700 characters to compare with the raw HTML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4faecbc-07a3-4311-9e45-4e6199db5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the website content\n",
    "url = \"https://www.cnn.com/2025/06/13/style/why-luxury-brands-are-so-expensive\"\n",
    "response = requests.get(url)         # get request for webpage\n",
    "html_content = response.text         # raw html text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708f03fe-7d92-4002-8efb-fba4efa012d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW HTML START:\n",
      "\n",
      "  <!DOCTYPE html>\n",
      "<html lang=\"en\" data-uri=\"cms.cnn.com/_pages/cmboyzvxs00d626qmalw1heqy@published\" data-layout-uri=\"cms.cnn.com/_layouts/layout-with-rail/instances/style-article-feature-v1@published\" >\n",
      "  <head>\n",
      "<link rel=\"dns-prefetch\" href=\"//tpc.googlesyndication.com\">\n",
      "\n",
      "<link rel=\"preconnect\" href=\"//tpc.googlesyndication.com\">\n",
      "\n",
      "<link rel=\"dns-prefetch\" href=\"//pagead2.googlesyndication.com\">\n",
      "\n",
      "<link rel=\"preconnect\" href=\"//pagead2.googlesyndication.com\">\n",
      "\n",
      "<link rel=\"dns-prefetch\" href=\"//www.googletagservices.com\">\n",
      "\n",
      "<link rel=\"preconnect\" href=\"//www.googletagservices.com\">\n",
      "\n",
      "<link rel=\"dns-prefetch\" href=\"//www.google.com\">\n",
      "\n",
      "<link rel=\"preconnect\" href=\"//www.google.com\">\n",
      "\n",
      "<link rel=\"dns\n"
     ]
    }
   ],
   "source": [
    "#to print only the first 700 chars of html to check\n",
    "print(\"RAW HTML START:\\n\")\n",
    "print(html_content[:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea1dc2a-0210-4e5b-b040-730c2937957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AFTER REMOVING HTML:\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Luxury brands are more expensive than ever. They’re telling you why they’re worth it | CNN\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CNN values your feedback\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                        1. How relevant is this ad to you?\n",
      "                                                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                2. Did you encounter any technical issues?\n",
      "                                        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                        Video player was slow to load content\n",
      "                                              \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#removing the html tags -> using beautifulsoup\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "text = soup.get_text()\n",
    "\n",
    "print(\"\\nAFTER REMOVING HTML:\\n\")\n",
    "print(text[:700])   # print first 700 chars of clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e380b4c-37cf-4ac1-ac93-bac22aa2dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the text lowercase and remove punctuation\n",
    "text = text.lower()   # all small letters\n",
    "text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)  # remove punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e750a784-02e3-459d-9e9c-c84e7d7de882",
   "metadata": {},
   "source": [
    "### Step 3: Lowercase & Remove Punctuation\n",
    "To normalize the text:\n",
    "- Convert everything to lowercase (so \"Luxury\" and \"luxury\" are treated the same).\n",
    "- Use regex to remove punctuation marks like `. , ! ?`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a80dc7-e21a-424e-9bb0-0b7149e2e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))  # list of common english words\n",
    "words = text.split()  # split into tokens\n",
    "filtered_words = [w for w in words if w not in stop_words]  # keep only important words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9902661d-63eb-4318-b49d-5b70a371dfcd",
   "metadata": {},
   "source": [
    "### Step 4: Remove Stopwords\n",
    "Stopwords are common words (like *the, is, and, to*) that don’t add much meaning.  \n",
    "I use NLTK’s built-in English stopword list and filter them out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8995be0-f2c1-49a7-a0bc-c94add2cd611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FIRST 50 LEMMATIZED WORDS:\n",
      "\n",
      "['luxury', 'brand', 'expensive', 'ever', 'they’re', 'telling', 'they’re', 'worth', 'cnn', 'cnn', 'value', 'feedback', '1', 'relevant', 'ad', '2', 'encounter', 'technical', 'issue', 'video', 'player', 'slow', 'load', 'content', 'video', 'content', 'never', 'loaded', 'ad', 'froze', 'finish', 'loading', 'video', 'content', 'start', 'ad', 'audio', 'ad', 'loud', 'issue', 'ad', 'never', 'loaded', 'ad', 'prevented', 'slowed', 'page', 'loading', 'content', 'moved']\n"
     ]
    }
   ],
   "source": [
    "#Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemm_words = [lemmatizer.lemmatize(w) for w in filtered_words]\n",
    "\n",
    "#To Print onnly first 50 words to check\n",
    "print(\"\\nFIRST 50 LEMMATIZED WORDS:\\n\")\n",
    "print(lemm_words[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d71fe4-f6c1-4fff-b85c-906cf9a12257",
   "metadata": {},
   "source": [
    "### Step 5: Lemmatization\n",
    "I use **WordNetLemmatizer** to reduce words to their dictionary base form.  \n",
    "Example: *\"running\" → \"run\"*, *\"cars\" → \"car\"*.  \n",
    "This makes the text cleaner for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d6c21-48c9-4e1d-aef4-f8da58344b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
