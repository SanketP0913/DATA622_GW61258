{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53453143-b95b-486d-9cc1-3d709883883e",
   "metadata": {},
   "source": [
    "# DATA 622 | Homework 9\n",
    "\n",
    "**Name:** Sanket Vijay Patil  \n",
    "**Date:** November 2025  \n",
    "**Campus ID** GW61258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e605607-16d6-4464-b9fd-5dfc8d22c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import pipeline\n",
    "from transformers import pipeline\n",
    "import re, collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b5b98c5-42aa-4324-b3cd-e3fe989a6dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article loaded successfully. Total length: 3307 characters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://apnews.com/article/boeing-aviation-aircraft-air-india-crash-f12b20e65dc57ae655a1e0759b58938f\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "paragraphs = [p.get_text() for p in soup.find_all(\"p\")]\n",
    "article = \"\\n\".join(paragraphs)\n",
    "print(\"Article loaded successfully. Total length:\", len(article), \"characters\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38fb68b6-b263-4f04-9c13-b24ba5777116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a101786bd88945479c7d14cbf0e4ff06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8eb4d08082f48409e81ab4ee3d91e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada2b88582434066aed20eede34c66c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e68ad5e5a604fb187d9282a5837250a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: {'NEGATIVE': 0.9992, 'POSITIVE': 0.0008}\n",
      "Direct forward sentiment: NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "import torch, math\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tok = AutoTokenizer.from_pretrained(model_id)\n",
    "mdl = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "mdl.eval()\n",
    "\n",
    "enc = tok(article, truncation=True, max_length=512, padding=\"max_length\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = mdl(**enc).logits[0]\n",
    "probs = torch.softmax(logits, dim=-1).tolist()\n",
    "labels = [\"NEGATIVE\", \"POSITIVE\"]\n",
    "sent_label = labels[int(torch.argmax(logits))]\n",
    "print(f\"Raw: {dict(zip(labels, [round(p,4) for p in probs]))}\")\n",
    "print(\"Direct forward sentiment:\", sent_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff3a475a-6760-4a1d-a09d-8701181d780e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot topics (%): {'technology': 33.02, 'aviation': 50.52, 'policy': 16.46}\n"
     ]
    }
   ],
   "source": [
    "z = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\",\n",
    "             device=-1, truncation=True, padding=True)\n",
    "LABELS = [\"technology\",\"aviation\",\"policy\"]\n",
    "\n",
    "def topics_zeroshot(text, labels=LABELS, chunk=900):\n",
    "    text = re.sub(r\"\\s+\",\" \", text).strip()\n",
    "    acc = collections.Counter({l:0.0 for l in labels}); n = 0\n",
    "    for i in range(0, len(text), chunk):\n",
    "        out = z(text[i:i+chunk], candidate_labels=labels, multi_label=True)\n",
    "        for l, s in zip(out[\"labels\"], out[\"scores\"]): acc[l] += float(s)\n",
    "        n += 1\n",
    "    avg = {l: acc[l]/max(1,n) for l in labels}\n",
    "    s = sum(avg.values()) or 1.0\n",
    "    return {l: round(100*avg[l]/s, 2) for l in labels}\n",
    "\n",
    "print(\"Zero-shot topics (%):\", topics_zeroshot(article))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04ce1b9a-6102-4381-bdd5-42742f1268b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DL Sentiment (chunked): neutral {'negative': 0.229, 'neutral': 0.771, 'positive': 0.0}\n"
     ]
    }
   ],
   "source": [
    "sent = pipeline(\"sentiment-analysis\",\n",
    "                model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "                device=-1, truncation=True, padding=True)\n",
    "\n",
    "def sentiment_chunked(txt, step=900):\n",
    "    txt = re.sub(r\"\\s+\",\" \", txt).strip()\n",
    "    acc = collections.Counter({\"negative\":0.0,\"neutral\":0.0,\"positive\":0.0})\n",
    "    n = 0\n",
    "    for i in range(0, len(txt), step):\n",
    "        r = sent(txt[i:i+step])[0]                 # {'label': 'Positive', 'score': ...}\n",
    "        acc[r[\"label\"].lower()] += float(r[\"score\"])\n",
    "        n += 1\n",
    "    s = sum(acc.values()) or 1.0\n",
    "    probs = {k: acc[k]/s for k in acc}\n",
    "    return max(probs, key=probs.get), {k: round(v,3) for k,v in probs.items()}\n",
    "\n",
    "label, probs = sentiment_chunked(article)\n",
    "print(\"\\nDL Sentiment:\", label, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "940e2c5b-189e-4f04-9f05-e31efd43d9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\summarizing the comparison\n",
      "LLM Sentiment : negative  | negative:0.76, positive:0.24, neutral:0.00\n",
      "DL  Sentiment : neutral   | negative:0.23, positive:0.00, neutral:0.77\n",
      "\n",
      "Top Emotions  : sadness (0.76), fear (0.13), neutral (0.04)\n",
      "\n",
      "Topic Relevance (%):\n",
      "  aviation     46.8%\n",
      "  technology   40.2%\n",
      "  policy       13.0%\n"
     ]
    }
   ],
   "source": [
    "#for fiinal summarization of results \n",
    "import re, collections\n",
    "from transformers import pipeline\n",
    "\n",
    "def _chunked(text, n=900):\n",
    "    text = re.sub(r\"\\s+\",\" \", str(text)).strip()\n",
    "    for i in range(0, len(text), n):\n",
    "        yield text[i:i+n]\n",
    "\n",
    "def sentiment_chunked(model_id, text, labels_expected):\n",
    "    clf = pipeline(\"sentiment-analysis\", model=model_id,\n",
    "                   device=-1, truncation=True, padding=True)\n",
    "    acc = collections.Counter({k:0.0 for k in labels_expected})\n",
    "    seen = 0\n",
    "    for c in _chunked(text, 900):\n",
    "        out = clf(c)[0]                               \n",
    "        lbl = out[\"label\"].lower()\n",
    "        if lbl not in acc:\n",
    "            if \"pos\" in lbl: lbl = \"positive\"\n",
    "            elif \"neg\" in lbl: lbl = \"negative\"\n",
    "            else: lbl = \"neutral\"\n",
    "        acc[lbl] += float(out[\"score\"]); seen += 1\n",
    "    s = sum(acc.values()) or 1.0\n",
    "    probs = {k: acc[k]/s for k in acc}\n",
    "    return max(probs, key=probs.get), probs\n",
    "\n",
    "def fmt_prob_map(d):\n",
    "    return \", \".join(f\"{k}:{v:.2f}\" for k,v in d.items())\n",
    "\n",
    "#Recomputing the  sentiments\n",
    "#SST-2 \n",
    "llm_label, llm_probs = sentiment_chunked(\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    article,\n",
    "    labels_expected={\"negative\",\"positive\",\"neutral\"}\n",
    ")\n",
    "\n",
    "#Cardiff Twitter RoBERTa\n",
    "dl_label, dl_probs = sentiment_chunked(\n",
    "    \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    article,\n",
    "    labels_expected={\"negative\",\"neutral\",\"positive\"}\n",
    ")\n",
    "\n",
    "topic_print = []\n",
    "try:\n",
    "    if isinstance(topic_scores, dict) and \"labels\" in topic_scores:\n",
    "        labs, scs = topic_scores[\"labels\"], topic_scores[\"scores\"]\n",
    "        s = sum(scs) or 1.0\n",
    "        topic_pct = {l: 100.0*float(sv)/s for l,sv in zip(labs, scs)}\n",
    "        topic_print = sorted(topic_pct.items(), key=lambda x: -x[1])\n",
    "    elif isinstance(topic_scores, dict):\n",
    "        s = sum(topic_scores.values()) or 1.0\n",
    "        topic_print = sorted(((k, 100.0*v/s) for k,v in topic_scores.items()), key=lambda x: -x[1])\n",
    "except Exception:\n",
    "    topic_print = []\n",
    "\n",
    "#Emotions\n",
    "top_emos_line = \"n/a\"\n",
    "try:\n",
    "    top_emos_line = \", \".join(f\"{e['label']} ({e['score']:.2f})\" for e in emo_sorted[:3])\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "#summary\n",
    "print(\"\\summarizing the comparison\")\n",
    "print(f\"LLM Sentiment : {llm_label}  | {fmt_prob_map(llm_probs)}\")\n",
    "print(f\"DL  Sentiment : {dl_label}   | {fmt_prob_map(dl_probs)}\")\n",
    "print(f\"\\nTop Emotions  : {top_emos_line}\")\n",
    "\n",
    "print(\"\\nTopic Relevance (%):\")\n",
    "if topic_print:\n",
    "    for k,v in topic_print:\n",
    "        print(f\"  {k:<10} {v:6.1f}%\")\n",
    "else:\n",
    "    print(\"  n/a\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ca0014-bfde-47cb-a05b-bc040d1bfbed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
