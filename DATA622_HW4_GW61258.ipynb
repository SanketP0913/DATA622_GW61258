{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c52c71b-d73d-486e-8e49-0dad44ecc8a1",
   "metadata": {},
   "source": [
    "# Sanket Vijay Patil\n",
    "# DATA622 HW4 \n",
    "# Campus ID:- GW61258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1643580-ca5c-46b7-8a58-249568c78cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package benepar_en3 to\n",
      "[nltk_data]     /Users/sanketpatil/nltk_data...\n",
      "[nltk_data]   Package benepar_en3 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk import Tree\n",
    "import benepar\n",
    "import benepar\n",
    "benepar.download('benepar_en3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f29546f-69d1-4f65-971c-458c18355283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanketpatil/jupyter_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# Load spaCy model and benepar\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Load benepar model\n",
    "if spacy.__version__.startswith('3'):\n",
    "    nlp.add_pipe('benepar', config={'model': 'benepar_en3'})\n",
    "else:\n",
    "    nlp.add_pipe(benepar.BeneparComponent(\"benepar_en3\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "142b53a3-c250-4d49-91d5-041028b3aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Four score and seven years ago our fathers brought forth on this continent, \n",
    "a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\n",
    "\n",
    "Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived \n",
    "and so dedicated, can long endure. We are met on a great battle-field of that war. We have come \n",
    "to dedicate a portion of that field, as a final resting place for those who here gave their lives \n",
    "that that nation might live. It is altogether fitting and proper that we should do this.\n",
    "\n",
    "But, in a larger sense, we can not dedicate -- we can not consecrate -- we can not hallow -- this ground. \n",
    "The brave men, living and dead, who struggled here, have consecrated it, far above our poor power to add \n",
    "or detract. The world will little note, nor long remember what we say here, but it can never forget what \n",
    "they did here. It is for us the living, rather, to be dedicated here to the unfinished work which they \n",
    "who fought here have thus far so nobly advanced. It is rather for us to be here dedicated to the great \n",
    "task remaining before us -- that from these honored dead we take increased devotion to that cause for \n",
    "which they gave the last full measure of devotion -- that we here highly resolve that these dead shall \n",
    "not have died in vain -- that this nation, under God, shall have a new birth of freedom -- and that \n",
    "government of the people, by the people, for the people, shall not perish from the earth.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8015120-adea-43ea-b8de-b361222a7acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text with spaCy...\n",
      "✓ Text processed successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Processing text with spaCy...\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# Get sentences\n",
    "sentences = list(doc.sents)\n",
    "first_sentence = sentences[0]\n",
    "second_sentence = sentences[1]\n",
    "\n",
    "print(\"✓ Text processed successfully\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2af0249a-da0d-498e-a554-a1f5972e2cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. TOKENIZATION\n",
      "\n",
      "--- First Sentence (spaCy) ---\n",
      "Sentence: Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.\n",
      "\n",
      "Tokens: ['Four', 'score', 'and', 'seven', 'years', 'ago', 'our', 'fathers', 'brought', 'forth', 'on', 'this', 'continent', ',', 'a', 'new', 'nation', ',', 'conceived', 'in', 'Liberty', ',', 'and', 'dedicated', 'to', 'the', 'proposition', 'that', 'all', 'men', 'are', 'created', 'equal', '.']\n",
      "Number of tokens: 34\n",
      "\n",
      "--- Second Sentence (spaCy) ---\n",
      "Sentence: Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure.\n",
      "\n",
      "Tokens: ['Now', 'we', 'are', 'engaged', 'in', 'a', 'great', 'civil', 'war', ',', 'testing', 'whether', 'that', 'nation', ',', 'or', 'any', 'nation', 'so', 'conceived', 'and', 'so', 'dedicated', ',', 'can', 'long', 'endure', '.']\n",
      "Number of tokens: 28\n",
      "\n",
      "--- Using benepar for tokenization ---\n",
      "Benepar uses the same tokenization through spaCy integration.\n",
      "First sentence tokens: ['Four', 'score', 'and', 'seven', 'years', 'ago', 'our', 'fathers', 'brought', 'forth', 'on', 'this', 'continent', ',', 'a', 'new', 'nation', ',', 'conceived', 'in', 'Liberty', ',', 'and', 'dedicated', 'to', 'the', 'proposition', 'that', 'all', 'men', 'are', 'created', 'equal', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"1. TOKENIZATION\")\n",
    "\n",
    "\n",
    "print(\"\\n--- First Sentence (spaCy) ---\")\n",
    "print(f\"Sentence: {first_sentence.text}\")\n",
    "print(f\"\\nTokens: {[token.text for token in first_sentence]}\")\n",
    "print(f\"Number of tokens: {len([token for token in first_sentence])}\")\n",
    "\n",
    "print(\"\\n--- Second Sentence (spaCy) ---\")\n",
    "print(f\"Sentence: {second_sentence.text}\")\n",
    "print(f\"\\nTokens: {[token.text for token in second_sentence]}\")\n",
    "print(f\"Number of tokens: {len([token for token in second_sentence])}\")\n",
    "\n",
    "print(\"\\n--- Using benepar for tokenization ---\")\n",
    "print(\"Benepar uses the same tokenization through spaCy integration.\")\n",
    "print(f\"First sentence tokens: {[token.text for token in first_sentence]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8d72c40-b20c-49e3-928f-8816afbb6eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. PART-OF-SPEECH TAGGING (First Sentence)\n",
      "\n",
      "Token                POS Tag         Description\n",
      "--------------------------------------------------------------------------------\n",
      "Four                 NUM             numeral\n",
      "score                NOUN            noun\n",
      "and                  CCONJ           coordinating conjunction\n",
      "seven                NUM             numeral\n",
      "years                NOUN            noun\n",
      "ago                  ADV             adverb\n",
      "our                  PRON            pronoun\n",
      "fathers              NOUN            noun\n",
      "brought              VERB            verb\n",
      "forth                ADV             adverb\n",
      "on                   ADP             adposition\n",
      "this                 DET             determiner\n",
      "continent            NOUN            noun\n",
      ",                    PUNCT           punctuation\n",
      "a                    DET             determiner\n",
      "new                  ADJ             adjective\n",
      "nation               NOUN            noun\n",
      ",                    PUNCT           punctuation\n",
      "conceived            VERB            verb\n",
      "in                   ADP             adposition\n",
      "Liberty              PROPN           proper noun\n",
      ",                    PUNCT           punctuation\n",
      "and                  CCONJ           coordinating conjunction\n",
      "dedicated            VERB            verb\n",
      "to                   ADP             adposition\n",
      "the                  DET             determiner\n",
      "proposition          NOUN            noun\n",
      "that                 SCONJ           subordinating conjunction\n",
      "all                  DET             determiner\n",
      "men                  NOUN            noun\n",
      "are                  AUX             auxiliary\n",
      "created              VERB            verb\n",
      "equal                ADJ             adjective\n",
      ".                    PUNCT           punctuation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"2. PART-OF-SPEECH TAGGING (First Sentence)\")\n",
    "\n",
    "\n",
    "print(f\"\\n{'Token':<20} {'POS Tag':<15} {'Description'}\")\n",
    "print(\"-\" * 80)\n",
    "for token in first_sentence:\n",
    "    print(f\"{token.text:<20} {token.pos_:<15} {spacy.explain(token.pos_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "164c17c2-3750-4e75-a709-fcec5119eef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. DEPENDENCY PARSING (Second Sentence)\n",
      "\n",
      "Token                Dependency      Head Word            Description\n",
      "--------------------------------------------------------------------------------\n",
      "Now                  advmod          engaged              adverbial modifier\n",
      "we                   nsubjpass       engaged              nominal subject (passive)\n",
      "are                  auxpass         engaged              auxiliary (passive)\n",
      "engaged              ccomp           endure               clausal complement\n",
      "in                   prep            engaged              prepositional modifier\n",
      "a                    det             war                  determiner\n",
      "great                amod            war                  adjectival modifier\n",
      "civil                amod            war                  adjectival modifier\n",
      "war                  pobj            in                   object of preposition\n",
      ",                    punct           engaged              punctuation\n",
      "testing              advcl           engaged              adverbial clause modifier\n",
      "whether              mark            conceived            marker\n",
      "that                 det             nation               determiner\n",
      "nation               nsubj           conceived            nominal subject\n",
      ",                    punct           nation               punctuation\n",
      "or                   cc              nation               coordinating conjunction\n",
      "any                  det             nation               determiner\n",
      "nation               conj            nation               conjunct\n",
      "so                   advmod          conceived            adverbial modifier\n",
      "conceived            ccomp           testing              clausal complement\n",
      "and                  cc              conceived            coordinating conjunction\n",
      "so                   advmod          dedicated            adverbial modifier\n",
      "dedicated            conj            conceived            conjunct\n",
      ",                    punct           endure               punctuation\n",
      "can                  aux             endure               auxiliary\n",
      "long                 advmod          endure               adverbial modifier\n",
      "endure               ROOT            endure               root\n",
      ".                    punct           endure               punctuation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"3. DEPENDENCY PARSING (Second Sentence)\")\n",
    "\n",
    "\n",
    "\n",
    "sentences = list(doc.sents)\n",
    "if len(sentences) > 1:\n",
    "    second_sentence = sentences[1]\n",
    "    print(f\"\\n{'Token':<20} {'Dependency':<15} {'Head Word':<20} {'Description'}\")\n",
    "    print(\"-\" * 80)\n",
    "    for token in second_sentence:\n",
    "        print(f\"{token.text:<20} {token.dep_:<15} {token.head.text:<20} \"\n",
    "              f\"{spacy.explain(token.dep_)}\")\n",
    "else:\n",
    "    print(\" Your text does not have a second sentence.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "754c8e09-fcb5-4543-871d-e6cfa21017fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. CONSTITUENT PARSING (First Sentence)\n",
      "\n",
      " Constituency Parse Tree\n",
      "(S (NP (CD Four) (NN score)) (CC and) (S (ADVP (NP (CD seven) (NNS years)) (RB ago)) (NP (PRP$ our) (NNS fathers)) (VP (VBD brought) (ADVP (RB forth)) (PP (IN on) (NP (DT this) (NN continent))) (, ,) (NP (NP (DT a) (JJ new) (NN nation)) (, ,) (VP (VBN conceived) (PP (IN in) (NP (NNP Liberty))))) (, ,) (CC and) (VP (VBN dedicated) (PP (IN to) (NP (DT the) (NN proposition) (SBAR (IN that) (S (NP (DT all) (NNS men)) (VP (VBP are) (VP (VBN created) (S (ADJP (JJ equal)))))))))))) (. .))\n",
      "\n",
      " Tree Structure\n",
      "(S (NP (CD Four) (NN score)) (CC and) (S (ADVP (NP (CD seven) (NNS years)) (RB ago)) (NP (PRP$ our) (NNS fathers)) (VP (VBD brought) (ADVP (RB forth)) (PP (IN on) (NP (DT this) (NN continent))) (, ,) (NP (NP (DT a) (JJ new) (NN nation)) (, ,) (VP (VBN conceived) (PP (IN in) (NP (NNP Liberty))))) (, ,) (CC and) (VP (VBN dedicated) (PP (IN to) (NP (DT the) (NN proposition) (SBAR (IN that) (S (NP (DT all) (NNS men)) (VP (VBP are) (VP (VBN created) (S (ADJP (JJ equal)))))))))))) (. .))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"4. CONSTITUENT PARSING (First Sentence)\")\n",
    "\n",
    "\n",
    "print(\"\\n Constituency Parse Tree\")\n",
    "sent = list(first_sentence.sents)[0]\n",
    "print(sent._.parse_string)\n",
    "\n",
    "#parsed tree in more readable format just to compare both results\n",
    "print(\"\\n Tree Structure\")\n",
    "def print_tree(sent, indent=0):\n",
    "    \"\"\"Print parse tree in indented format\"\"\"\n",
    "    tree_str = sent._.parse_string\n",
    "    print(tree_str)\n",
    "\n",
    "print(sent._.parse_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d0a5471-c9fc-450a-8ef5-732b1bad1209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. EXTRACT NOUN PHRASES\n",
      "\n",
      " First Sentence Noun Phrases \n",
      "1. 'Four score' (Root: score, Dependency: nsubj)\n",
      "2. 'our fathers' (Root: fathers, Dependency: nsubj)\n",
      "3. 'this continent' (Root: continent, Dependency: pobj)\n",
      "4. 'a new nation' (Root: nation, Dependency: dobj)\n",
      "5. 'Liberty' (Root: Liberty, Dependency: pobj)\n",
      "6. 'the proposition' (Root: proposition, Dependency: pobj)\n",
      "7. 'all men' (Root: men, Dependency: nsubjpass)\n",
      "\n",
      " Second Sentence Noun Phrases \n",
      "1. 'we' (Root: we, Dependency: nsubjpass)\n",
      "2. 'a great civil war' (Root: war, Dependency: pobj)\n",
      "3. 'that nation' (Root: nation, Dependency: nsubj)\n",
      "4. 'any nation' (Root: nation, Dependency: conj)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"5. EXTRACT NOUN PHRASES\")\n",
    "\n",
    "print(\"\\n First Sentence Noun Phrases \")\n",
    "for i, chunk in enumerate(first_sentence.noun_chunks, 1):\n",
    "    print(f\"{i}. '{chunk.text}' (Root: {chunk.root.text}, Dependency: {chunk.root.dep_})\")\n",
    "\n",
    "print(\"\\n Second Sentence Noun Phrases \")\n",
    "for i, chunk in enumerate(second_sentence.noun_chunks, 1):\n",
    "    print(f\"{i}. '{chunk.text}' (Root: {chunk.root.text}, Dependency: {chunk.root.dep_})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5a095f2-163e-4bed-961b-335d5f86a377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 6: CRF AND HMM\n",
      "\n",
      "Why use CRF and HMM? How do they differ? \n",
      "\n",
      "While reading this paper (https://www.baeldung.com/cs/hidden-markov-vs-crf),\n",
      "I found that:\n",
      "\n",
      "HMMs are generative models using joint probability distributions for sequential \n",
      "labeling tasks. CRFs are discriminative models using conditional probabilities, avoiding \n",
      "independence assumptions. CRFs handle overlapping features better and typically outperform \n",
      "HMMs in NLP sequence labeling tasks.\n",
      "\n",
      " Key Differences from the Paper \n",
      "• HMM: Generative model (models P(X,Y))\n",
      "• CRF: Discriminative model (models P(Y|X))\n",
      "• HMM: Assumes feature independence\n",
      "• CRF: No independence assumptions, handles feature dependencies\n",
      "• CRF: Better for real-world NLP tasks (POS tagging, NER)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"QUESTION 6: CRF AND HMM\")\n",
    "\n",
    "\n",
    "print(\"\\nWhy use CRF and HMM? How do they differ? \\n\")\n",
    "\n",
    "print(\"While reading this paper (https://www.baeldung.com/cs/hidden-markov-vs-crf),\")\n",
    "print(\"I found that:\\n\")\n",
    "\n",
    "summary = \"\"\"HMMs are generative models using joint probability distributions for sequential \n",
    "labeling tasks. CRFs are discriminative models using conditional probabilities, avoiding \n",
    "independence assumptions. CRFs handle overlapping features better and typically outperform \n",
    "HMMs in NLP sequence labeling tasks.\"\"\"\n",
    "\n",
    "print(summary.strip())\n",
    "\n",
    "\n",
    "print(\"\\n Key Differences from the Paper \")\n",
    "print(\"• HMM: Generative model (models P(X,Y))\")\n",
    "print(\"• CRF: Discriminative model (models P(Y|X))\")\n",
    "print(\"• HMM: Assumes feature independence\")\n",
    "print(\"• CRF: No independence assumptions, handles feature dependencies\")\n",
    "print(\"• CRF: Better for real-world NLP tasks (POS tagging, NER)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c56ef-b4b1-42b1-9a7e-4703205455c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61f6126-4a4b-41a1-95c3-3ff9aa471895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
