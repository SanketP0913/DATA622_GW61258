{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad764ee6-9271-4d4c-8253-ea2d5c40f700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trafilatura\n",
      "  Downloading trafilatura-2.0.0-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 9.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting justext>=3.0.1\n",
      "  Downloading justext-3.0.2-py2.py3-none-any.whl (837 kB)\n",
      "\u001b[K     |████████████████████████████████| 837 kB 34.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lxml>=5.3.0\n",
      "  Downloading lxml-6.0.2-cp39-cp39-macosx_10_9_universal2.whl (8.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.6 MB 28.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting courlan>=1.3.2\n",
      "  Downloading courlan-1.3.2-py3-none-any.whl (33 kB)\n",
      "Collecting htmldate>=1.9.2\n",
      "  Downloading htmldate-1.9.3-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: charset_normalizer>=3.4.0 in ./jupyter_env/lib/python3.9/site-packages (from trafilatura) (3.4.3)\n",
      "Requirement already satisfied: certifi in ./jupyter_env/lib/python3.9/site-packages (from trafilatura) (2025.8.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in ./jupyter_env/lib/python3.9/site-packages (from trafilatura) (1.26.20)\n",
      "Requirement already satisfied: babel>=2.16.0 in ./jupyter_env/lib/python3.9/site-packages (from courlan>=1.3.2->trafilatura) (2.17.0)\n",
      "Collecting tld>=0.13\n",
      "  Downloading tld-0.13.1-py2.py3-none-any.whl (274 kB)\n",
      "\u001b[K     |████████████████████████████████| 274 kB 49.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lxml>=5.3.0\n",
      "  Downloading lxml-5.4.0-cp39-cp39-macosx_10_9_universal2.whl (8.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.1 MB 14.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.9.0.post0 in ./jupyter_env/lib/python3.9/site-packages (from htmldate>=1.9.2->trafilatura) (2.9.0.post0)\n",
      "Collecting dateparser>=1.1.2\n",
      "  Downloading dateparser-1.2.2-py3-none-any.whl (315 kB)\n",
      "\u001b[K     |████████████████████████████████| 315 kB 28.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2024.2 in ./jupyter_env/lib/python3.9/site-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2025.2)\n",
      "Collecting tzlocal>=0.2\n",
      "  Downloading tzlocal-5.3.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: regex>=2024.9.11 in ./jupyter_env/lib/python3.9/site-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2025.9.1)\n",
      "\u001b[33mWARNING: lxml 6.0.2 does not provide the extra 'html_clean'\u001b[0m\n",
      "Collecting lxml[html_clean]>=4.4.2\n",
      "  Downloading lxml-6.0.1-cp39-cp39-macosx_10_9_universal2.whl (8.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.4 MB 38.1 MB/s eta 0:00:01\n",
      "\u001b[33mWARNING: lxml 6.0.1 does not provide the extra 'html_clean'\u001b[0m\n",
      "\u001b[?25h  Downloading lxml-6.0.0-cp39-cp39-macosx_10_9_universal2.whl (8.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.4 MB 10.7 MB/s eta 0:00:01\n",
      "\u001b[33mWARNING: lxml 6.0.0 does not provide the extra 'html_clean'\u001b[0m\n",
      "\u001b[33mWARNING: lxml 5.4.0 does not provide the extra 'html_clean'\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in ./jupyter_env/lib/python3.9/site-packages (from python-dateutil>=2.9.0.post0->htmldate>=1.9.2->trafilatura) (1.17.0)\n",
      "Installing collected packages: tzlocal, lxml, tld, dateparser, justext, htmldate, courlan, trafilatura\n",
      "Successfully installed courlan-1.3.2 dateparser-1.2.2 htmldate-1.9.3 justext-3.0.2 lxml-5.4.0 tld-0.13.1 trafilatura-2.0.0 tzlocal-5.3.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Users/sanketpatil/jupyter_env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "    !pip install trafilatura\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd17cf14-d324-4a80-9cc4-9079b2c7c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trafilatura\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a97ae9a-059c-4a79-97fb-5e8e70105d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK data ready\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "print(\"NLTK data ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e319f99-cb05-4947-9301-62bb8ae0043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.usatoday.com/story/news/politics/2025/06/13/pete-hegseth-pentagon-invade-greenland-plan/84188458007/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "292e0c37-0ecc-4b43-b319-666f9d83f4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded = trafilatura.fetch_url(url)\n",
    "article = trafilatura.extract(downloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f47ca168-ae7b-4e92-b702-c557378a9852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article fetched: 1732 characters, 13 sentences\n",
      "\n",
      "First 300 characters:\n",
      "Hegseth says Pentagon has many 'contingencies' in Greenland - including invading it\n",
      "Defense Secretary Pete Hegseth said the Pentagon has plans for multiple \"contingencies\" in Greenland – including an invasion of the island.\n",
      "Asked by Republican Rep. Mike Turner at a June 12 House Armed Services Commi...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "sentences = sent_tokenize(article)\n",
    "\n",
    "print(f\"Article fetched: {len(article)} characters, {len(sentences)} sentences\")\n",
    "print(f\"\\nFirst 300 characters:\\n{article[:300]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60a56cfb-a06d-4469-bf27-5b43d0502c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Algorithm: Graph-based ranking (like Google PageRank)\n",
      "Method: Extracts most central sentences based on similarity\n",
      "\n",
      "--- TEXTRANK SUMMARY ---\n",
      "\n",
      "Hegseth says Pentagon has many 'contingencies' in Greenland - including invading it\n",
      "Defense Secretary Pete Hegseth said the Pentagon has plans for multiple \"contingencies\" in Greenland – including an invasion of the island. \"It is not your testimony today that there are plans at the Pentagon for taking by force or invading Greenland, correct? During a March visit to Pituffik Space Base, the U.S. base on Greenland, Vice President JD Vance accused Denmark of \"failing\" to protect the Arctic island while downplaying Trump's threats to take it over by force.\n",
      "\n",
      " Extracted 3 sentences\n"
     ]
    }
   ],
   "source": [
    "def textrank_summary(text, num_sentences=3):\n",
    "\n",
    "    #Splitting text \n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    if len(sentences) < num_sentences:\n",
    "        return text\n",
    "    \n",
    "    #Converting the sentences to TF-IDF vectors\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "    \n",
    "    #Calculatimg the similarity between all sentence pairs\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    #graph of similarities in matrix\n",
    "    nx_graph = nx.from_numpy_array(similarity_matrix)\n",
    "    \n",
    "    #PageRank algorithm\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    \n",
    "    #Ranking the sentences\n",
    "    ranked_sentences = sorted(\n",
    "        ((scores[i], s) for i, s in enumerate(sentences)), \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    #selcting top sentences\n",
    "    top_sentences = sorted(\n",
    "        ranked_sentences[:num_sentences], \n",
    "        key=lambda x: sentences.index(x[1])\n",
    "    )\n",
    "    \n",
    "    return ' '.join([sent for score, sent in top_sentences])\n",
    "\n",
    "#Generating the TextRank summary\n",
    "print(\"\\nAlgorithm: Graph-based ranking (like Google PageRank)\")\n",
    "print(\"Method: Extracts most central sentences based on similarity\")\n",
    "print(\"\\n--- TEXTRANK SUMMARY ---\\n\")\n",
    "\n",
    "textrank_result = textrank_summary(article, num_sentences=3)\n",
    "print(textrank_result)\n",
    "print(f\"\\n Extracted {len(sent_tokenize(textrank_result))} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71845314-99aa-4aba-8527-41d70145615d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 2: FREQUENCY-BASED SENTENCE SCORING\n",
      "\n",
      "Algorithm: Word frequency scoring\n",
      "Method: Extracts sentences with highest-frequency words\n",
      "\n",
      "FREQUENCY-BASED SUMMARY \n",
      "\n",
      "Hegseth says Pentagon has many 'contingencies' in Greenland - including invading it\n",
      "Defense Secretary Pete Hegseth said the Pentagon has plans for multiple \"contingencies\" in Greenland – including an invasion of the island. \"It is not your testimony today that there are plans at the Pentagon for taking by force or invading Greenland, correct? \"The U.S. shall not take over Greenland.\n",
      "\n",
      " Extracted 3 sentences\n"
     ]
    }
   ],
   "source": [
    "print(\"QUESTION 2: FREQUENCY-BASED SENTENCE SCORING\")\n",
    "\n",
    "def frequency_based_summary(text, num_sentences=3):\n",
    "\n",
    "    #splitting into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    if len(sentences) < num_sentences:\n",
    "        return text\n",
    "    \n",
    "    #tokenization of text into words and convert to lowercase\n",
    "    words = word_tokenize(text.lower())\n",
    "    \n",
    "    #Removing the stopwords and non-alphanumeric tokens\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if w.isalnum() and w not in stop_words]\n",
    "    \n",
    "    #Counting word frequencies\n",
    "    word_freq = Counter(words)\n",
    "    \n",
    "\n",
    "    sentence_scores = {}\n",
    "    for sentence in sentences:\n",
    "        sentence_words = word_tokenize(sentence.lower())\n",
    "        sentence_words = [w for w in sentence_words if w.isalnum() and w not in stop_words]\n",
    "        \n",
    "        if len(sentence_words) > 0:\n",
    "            total_score = sum(word_freq.get(word, 0) for word in sentence_words)\n",
    "            sentence_scores[sentence] = total_score / len(sentence_words)\n",
    "    \n",
    "    #Ranking the sentences by score\n",
    "    ranked_sentences = sorted(\n",
    "        sentence_scores.items(), \n",
    "        key=lambda x: x[1], \n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    #Selecting top N sentences\n",
    "    top_sentences = sorted(\n",
    "        ranked_sentences[:num_sentences], \n",
    "        key=lambda x: sentences.index(x[0])\n",
    "    )\n",
    "    \n",
    "    return ' '.join([sent for sent, score in top_sentences])\n",
    "\n",
    "# Generating frequency-based summary\n",
    "print(\"\\nAlgorithm: Word frequency scoring\")\n",
    "print(\"Method: Extracts sentences with highest-frequency words\")\n",
    "print(\"\\nFREQUENCY-BASED SUMMARY \\n\")\n",
    "\n",
    "freq_result = frequency_based_summary(article, num_sentences=3)\n",
    "print(freq_result)\n",
    "print(f\"\\n Extracted {len(sent_tokenize(freq_result))} sentences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7cbeb48-9a30-4a9e-bcad-076cae53109a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 3: ABSTRACTIVE SUMMARY (BART TRANSFORMER)\n",
      "\n",
      "Algorithm: Neural transformer model (BART)\n",
      "Method: Generates new text (not extraction)\n",
      "Model: facebook/bart-large-cnn (pre-trained on CNN/DailyMail)\n",
      "\n",
      "Loading BART model (may take 1-2 minutes on first run)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating abstractive summary...\n",
      "\n",
      "   BART ABSTRACTIVE SUMMARY \n",
      "\n",
      "Defense Secretary Pete Hegseth said the Pentagon has plans for multiple \"contingencies\" in Greenland – including an invasion of the island. President Donald Trump has declined to rule out force in his pledge to \"get Greenland,\" although he has said it won't be necessary. He has insisted acquiring Greenland is necessary for national security.\n",
      "\n",
      " Generated new text using neural model\n"
     ]
    }
   ],
   "source": [
    "print(\"QUESTION 3: ABSTRACTIVE SUMMARY (BART TRANSFORMER)\")\n",
    "\n",
    "print(\"\\nAlgorithm: Neural transformer model (BART)\")\n",
    "print(\"Method: Generates new text (not extraction)\")\n",
    "print(\"Model: facebook/bart-large-cnn (pre-trained on CNN/DailyMail)\")\n",
    "\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "    \n",
    "    print(\"\\nLoading BART model (may take 1-2 minutes on first run)...\")\n",
    "    \n",
    "    #pipeline creation \n",
    "    summarizer = pipeline(\n",
    "        \"summarization\", \n",
    "        model=\"facebook/bart-large-cnn\",\n",
    "        device=-1\n",
    "    )\n",
    "    \n",
    "    max_words = 1000\n",
    "    input_text = article if len(article.split()) < max_words else ' '.join(article.split()[:max_words])\n",
    "    \n",
    "    print(\"Generating abstractive summary...\\n\")\n",
    "\n",
    "    result = summarizer(\n",
    "        input_text, \n",
    "        max_length=150, \n",
    "        min_length=50, \n",
    "        do_sample=False\n",
    "    )\n",
    "    \n",
    "    print(\"   BART ABSTRACTIVE SUMMARY \\n\")\n",
    "    print(result[0]['summary_text'])\n",
    "    print(f\"\\n Generated new text using neural model\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"\\n error while importing file try something else\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n Error: {str(e)[:100]}\")\n",
    "    print(\"Eroor \")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"\\n error while importing the file try something nelse\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n Error: {str(e)[:100]}\")\n",
    "    print(\"\\n error \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6aae9849-b0e9-4afb-8338-abe61d7e7849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 4: LEAD-3 SUMMARY\n",
      "\n",
      "Algorithm: Baseline method\n",
      "Method: Extract first 3 sentences (inverted pyramid structure)\n",
      "\n",
      "    LEAD-3 SUMMARY \n",
      "\n",
      "Hegseth says Pentagon has many 'contingencies' in Greenland - including invading it\n",
      "Defense Secretary Pete Hegseth said the Pentagon has plans for multiple \"contingencies\" in Greenland – including an invasion of the island. Asked by Republican Rep. Mike Turner at a June 12 House Armed Services Committee hearing to confirm whether there are plans to invade Greenland, Hegseth said, \"The Pentagon has plans for any number of contingencies.\" \"It is not your testimony today that there are plans at the Pentagon for taking by force or invading Greenland, correct?\n",
      "\n",
      " Extracted first 3 sentences\n"
     ]
    }
   ],
   "source": [
    "print(\"QUESTION 4: LEAD-3 SUMMARY\")\n",
    "\n",
    "\n",
    "print(\"\\nAlgorithm: Baseline method\")\n",
    "print(\"Method: Extract first 3 sentences (inverted pyramid structure)\")\n",
    "print(\"\\n    LEAD-3 SUMMARY \\n\")\n",
    "\n",
    "# Simply take first 3 sentences\n",
    "lead3_result = ' '.join(sentences[:3])\n",
    "\n",
    "print(lead3_result)\n",
    "print(f\"\\n Extracted first 3 sentences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77f26086-72c2-4065-8692-a69b33e54b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 5: MANUAL COMPRESSION SUMMARY (20%)\n",
      "\n",
      "Algorithm: Frequency-based compression\n",
      "Method: Extract top 20% of sentences by importance\n",
      "\n",
      "Original: 13 sentences\n",
      "Target (20%): 2 sentences\n",
      "Compression: 13 → 2 (15.4%)\n",
      "\n",
      "    COMPRESSION SUMMARY (20%) \n",
      "\n",
      "\"It is not your testimony today that there are plans at the Pentagon for taking by force or invading Greenland, correct? \"The U.S. shall not take over Greenland.\n",
      "\n",
      " Compressed to 2 sentences\n"
     ]
    }
   ],
   "source": [
    "print(\"QUESTION 5: MANUAL COMPRESSION SUMMARY (20%)\")\n",
    "\n",
    "\n",
    "#target number of sentences (20% of original)\n",
    "total_sentences = len(sentences)\n",
    "num_sentences_20pct = max(1, int(total_sentences * 0.2))\n",
    "\n",
    "print(f\"\\nAlgorithm: Frequency-based compression\")\n",
    "print(f\"Method: Extract top 20% of sentences by importance\")\n",
    "print(f\"\\nOriginal: {total_sentences} sentences\")\n",
    "print(f\"Target (20%): {num_sentences_20pct} sentences\")\n",
    "print(f\"Compression: {total_sentences} → {num_sentences_20pct} ({(num_sentences_20pct/total_sentences)*100:.1f}%)\")\n",
    "\n",
    "def compression_summary(text, percentage=0.2):\n",
    "\n",
    "    sentences = sent_tokenize(text)\n",
    "    num_sentences = max(1, int(len(sentences) * percentage))\n",
    "    return frequency_based_summary(text, num_sentences=num_sentences)\n",
    "\n",
    "print(\"\\n    COMPRESSION SUMMARY (20%) \\n\")\n",
    "\n",
    "compression_result = compression_summary(article, percentage=0.2)\n",
    "print(compression_result)\n",
    "print(f\"\\n Compressed to {len(sent_tokenize(compression_result))} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1736bafc-6045-4124-a84f-1f8e4f2fc7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 6: LLM SUMMARY\n",
      "\n",
      "Algorithm: Large Language Model\n",
      "Method: Advanced neural model with billions of parameters\n",
      "Note: This is a simulated LLM summary for demonstration\n",
      "\n",
      "    LLM-STYLE SUMMARY \n",
      "\n",
      "Defense Secretary Pete Hegseth faced scorching questioning during a congressional hearing \n",
      "in which he appeared to affirm Pentagon contingency plans for potential military action in Greenland and Panama. \n",
      "The hearing turned heated as Democratic legislators questioned Hegseth about his use of Signal messaging to discuss \n",
      "sensitive military activities, such as strikes against Houthi rebels in Yemen. Hegseth dodged straight answers repeatedly, citing\n",
      "position at the \"pleasure of the president\" while claiming the Pentagon has plans\n",
      "for \"any contingency.\" The scandal is against the backdrop of President Trump's\n",
      "repeated assertion that he would like to buy Greenland, which has been firmly rebuffed by its leaders.\n",
      "\n",
      " Generated coherent narrative summary\n",
      "TO USE REAL LLM API (e.g., OpenAI GPT):\n",
      "\n",
      "# Install: pip install openai\n",
      "import openai\n",
      "\n",
      "client = openai.OpenAI(api_key='your-api-key-here')\n",
      "response = client.chat.completions.create(\n",
      "    model='gpt-4',\n",
      "    messages=[\n",
      "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
      "        {'role': 'user', 'content': f'Summarize this article concisely: {article}'}\n",
      "    ],\n",
      "    max_tokens=200\n",
      ")\n",
      "print(response.choices[0].message.content)\n",
      "\n",
      "COMPARISON OF ALL METHODS\n",
      "\n",
      "Method                         Sentences    Characters   Type\n",
      "Original Article               13           1732         Full text\n",
      "1. TextRank                    3            559          Extractive\n",
      "2. Frequency-Based             3            385          Extractive\n",
      "3. BART (Abstractive)          Variable     Variable     Abstractive\n",
      "4. Lead-3                      3            561          Extractive\n",
      "5. Compression (20%)           2            161          Extractive\n",
      "6. LLM                         4            716          Abstractive\n"
     ]
    }
   ],
   "source": [
    "print(\"QUESTION 6: LLM SUMMARY\")\n",
    "\n",
    "print(\"\\nAlgorithm: Large Language Model\")\n",
    "print(\"Method: Advanced neural model with billions of parameters\")\n",
    "print(\"Note: This is a simulated LLM summary for demonstration\")\n",
    "\n",
    "\n",
    "llm_summary = \"\"\"Defense Secretary Pete Hegseth faced scorching questioning during a congressional hearing \n",
    "in which he appeared to affirm Pentagon contingency plans for potential military action in Greenland and Panama. \n",
    "The hearing turned heated as Democratic legislators questioned Hegseth about his use of Signal messaging to discuss \n",
    "sensitive military activities, such as strikes against Houthi rebels in Yemen. Hegseth dodged straight answers repeatedly, citing\n",
    "position at the \"pleasure of the president\" while claiming the Pentagon has plans\n",
    "for \"any contingency.\" The scandal is against the backdrop of President Trump's\n",
    "repeated assertion that he would like to buy Greenland, which has been firmly rebuffed by its leaders.\"\"\"\n",
    "\n",
    "print(\"\\n    LLM-STYLE SUMMARY \\n\")\n",
    "print(llm_summary)\n",
    "print(f\"\\n Generated coherent narrative summary\")\n",
    "\n",
    "# Show example code for real LLM API usage\n",
    "print(\"TO USE REAL LLM API (e.g., OpenAI GPT):\")\n",
    "\n",
    "print(\"\"\"\n",
    "# Install: pip install openai\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key='your-api-key-here')\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4',\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "        {'role': 'user', 'content': f'Summarize this article concisely: {article}'}\n",
    "    ],\n",
    "    max_tokens=200\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"COMPARISON OF ALL METHODS\")\n",
    "\n",
    "print(f\"\\n{'Method':<30} {'Sentences':<12} {'Characters':<12} {'Type'}\")\n",
    "\n",
    "\n",
    "comparison_data = [\n",
    "    (\"Original Article\", total_sentences, len(article), \"Full text\"),\n",
    "    (\"1. TextRank\", len(sent_tokenize(textrank_result)), len(textrank_result), \"Extractive\"),\n",
    "    (\"2. Frequency-Based\", len(sent_tokenize(freq_result)), len(freq_result), \"Extractive\"),\n",
    "    (\"3. BART (Abstractive)\", \"Variable\", \"Variable\", \"Abstractive\"),\n",
    "    (\"4. Lead-3\", len(sent_tokenize(lead3_result)), len(lead3_result), \"Extractive\"),\n",
    "    (\"5. Compression (20%)\", len(sent_tokenize(compression_result)), len(compression_result), \"Extractive\"),\n",
    "    (\"6. LLM\", len(sent_tokenize(llm_summary)), len(llm_summary), \"Abstractive\")\n",
    "]\n",
    "\n",
    "for method, sents, chars, type_method in comparison_data:\n",
    "    print(f\"{method:<30} {str(sents):<12} {str(chars):<12} {type_method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8348317-2496-4598-afae-8d692483c13f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
